{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IMPORTS\n",
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic Constants\n",
    "\n",
    "DATA = \"data/demo.csv\"\n",
    "OUTCOME = \"Y\"\n",
    "NUM_TRAIN = 800"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diabetes Constants\n",
    "\n",
    "DATA = \"data/diabetes_binary.csv\"\n",
    "OUTCOME = \"Outcome\"\n",
    "NUM_TRAIN = 600"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Synthetic Data\n",
    "\n",
    "Generates synthetic data according to a series of functions defined in generating_functions that basically make up a function graph. \n",
    "\n",
    "Data Descriptions:\n",
    "\n",
    "- demo: Generated with function graph based on the DAG in figure TODO in paper (used for demoing purposes)\n",
    "- standard: Generated with function graph based on the DAG in figure TODO in paper\n",
    "- upstream_shift: Generated with function graph based on the DAG in figure TODO in paper with a significant change to one of the generating functions of a variables that comes before Y in a topological ordering to be used for distribution shift testing\n",
    "- downstream_shift: Generated with function graph based on the DAG in figure TODO in paper with a significant change to one of the generating functions of a variables that comes after Y in a topological ordering to be used for distribution shift testing\n",
    "\n",
    "- mixed_standard: Generated with function graph based on the ADMG in figure TODO in paper\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### GENERATE DATA\n",
    "\n",
    "from generatedata import generate\n",
    "\n",
    "# generating_functions contants several function nets to generate random data\n",
    "from generating_functions import demo, standard, mixed_standard, upstream_shift, downstream_shift\n",
    "\n",
    "\n",
    "generating_data = demo\n",
    "\n",
    "starting_names = generating_data[\"starting_names\"]\n",
    "starting_generating_boundaries = generating_data[\"starting_generating_boundaries\"] \n",
    "downstream_names = generating_data[\"downstream_names\"]\n",
    "downstream_generating_functions = generating_data[\"downstream_generating_functions\"]\n",
    "downstream_parents = generating_data[\"downstream_parents\"]\n",
    "data = generate(starting_names, starting_generating_boundaries, downstream_names, downstream_generating_functions, downstream_parents, 1000)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(generating_data[\"name\"], index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BINARIZE DATA\n",
    "\n",
    "from binarize import binarize\n",
    "\n",
    "binarize(generating_data[\"name\"], generating_data[\"name\"])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Real Data\n",
    "\n",
    "You can import real data in as a csv file and run the same analysis. This software can only handle binary variables so most real world data will need to be cleaned first.\n",
    "\n",
    "The cell will clean the data so that it can run in the software but you may lose more information that you want. It removes all rows with non-numeric typed data and then binarizes everything that is left.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### CLEAN DATA\n",
    "# Only need this if using real data\n",
    "\n",
    "from fix import remove_strs\n",
    "\n",
    "remove_strs(DATA)\n",
    "binarize(DATA, DATA)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the following cell to load whatever data you are using\n",
    "\n",
    "The data MUST be binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### READ DATA\n",
    "\n",
    "df = pd.read_csv(DATA)\n",
    "df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Making the Causal Graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Dag Drawing Software\n",
    "\n",
    "pass and nodes and edges that you want to be preloaded into the software by changing the nodes and edges lists below\n",
    "\n",
    "Some Useful commands when adding nodes:\n",
    "\n",
    "- click: adds node\n",
    "- shift+click: moves nearby node to second click (node to move will turn green)\n",
    "- m: Your next click will select a nearby node to be moved and the following will place it\n",
    "- Esc: cancels current action\n",
    "\n",
    "Some Useful commands when adding Edges:\n",
    "\n",
    "- click 2x: first click starts edge from nearby node and second click connects edge to second node. Note first click is a parent of second click (parent node will turn red)\n",
    "- Esc: cancels current edge\n",
    "\n",
    "\n",
    "General Useful commands:\n",
    "\n",
    "- Cmd-z: Undo\n",
    "- Cmd-shift-z: Redo\n",
    "- t: toggle between adding nodes and edges\n",
    "- p: Returns nodes and edges \n",
    "\n",
    "\n",
    "Currently only works for DAGs but you can still print out the directed edges for a ADMG, just make sure to change it from saying \"edges\" to \"di_edges\" and then enter the bi_edges in the manual entry phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DAG DRAWING SOFTWARE\n",
    "# ADMG drawer coming soon\n",
    "\n",
    "nodes = list(df.columns)\n",
    "edges = []\n",
    "\n",
    "_ = os.system(f\"python run_dag_draw.py \\\"{str(nodes)}\\\" \\\"{str(edges)}\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### COPY AND RUN OUTPUT OF ABOVE CELL HERE\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 2: Causal Discovery\n",
    "\n",
    "If you think there is unmeasured confounding in your data run the ADMG discovery cell, otherwise run the DAG discovery. \n",
    "\n",
    "You can enter any prior knowledge using the box below\n",
    "\n",
    "This software requires all edges to be oriented, to do that run the FIX DAG /ADMG cell to finish orienting edges with user knowledge. \n",
    "\n",
    "Note: to quit the edge fixing protocol enter q\n",
    "\n",
    "Important: This is NOT guaranteed to not generate new cycles so be cautions with how edges are oriented.\n",
    "\n",
    "DAG Edges:\n",
    "\n",
    "Blue edges of form X --> Y means X causes Y\n",
    "Brown edges of form X --- Y reprisent edges that could either be oriented X --> Y or Y --> X.\n",
    "\n",
    "ADMG Edges:\n",
    "\n",
    "Blue edges of form X --> Y means X causes Y\n",
    "Red edges of form X <-> Y reprisent unmeasured confounding between X and Y\n",
    "Green edges of form X --> Y really should be of form X o-> Y. This means either X --> Y or X <-> Y or both.\n",
    "Orange edges of form X --- Y really should be of form X o-o Y. This means either 1) X --> Y, 2) Y --> X, 3) X <-> Y, 1 and 3, or 2 and 3\n",
    "\n",
    "You can also add prior knowledge to the graph before running a search in the form of tiers. To do this create a file containing the knowlege then updating the knowledge=None to be knowledge=\\<filename\\>. A knowledge file is formatted as follows:\n",
    "\n",
    "\n",
    "[tier num] nodes in tier\n",
    "\n",
    "\n",
    "[tier num] nodes in tier\n",
    "\n",
    "\n",
    "Example:\n",
    "\n",
    "1 Age\n",
    "\n",
    "2 Pregnancies DiabetesPedigreeFunction Outcome BMI SkinThickness BloodPressure Insulin Glucose\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DAG DISCOVERY\n",
    "from discovery import run_pc, draw\n",
    "\n",
    "nodes, edges = run_pc(DATA, knowledge=None)\n",
    "\n",
    "draw(nodes, edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADMG DISCOVERY\n",
    "from discovery import run_fci, draw\n",
    "\n",
    "nodes, edges = run_fci(DATA)#, knowledge=\"knowledge.txt\")\n",
    "\n",
    "draw(nodes, edges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### FIX GRAPHS\n",
    "\n",
    "from fix import fix_graph\n",
    "\n",
    "graph_data = fix_graph(nodes, edges)\n",
    "\n",
    "if len(graph_data) == 3:\n",
    "    nodes, di_edges, bi_edges = graph_data\n",
    "    to_draw = (nodes, di_edges, bi_edges)\n",
    "\n",
    "    \n",
    "else: \n",
    "    nodes, edges = graph_data\n",
    "    to_draw = nodes, edges\n",
    "    \n",
    "draw(*to_draw)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 3: Manual Entry\n",
    "\n",
    "Here you can manually enter nodes and edges if you want instead. \n",
    "\n",
    "I also provide 3 graph dictionaries that contain prestored data.\n",
    "- standard_synthetic: this is the DAG outlined in figure TODO of the paper\n",
    "- mixed_synthetic: this is the ADMG outlined in figure TODO of the paper\n",
    "- diabetes: this is a DAG of the diabetes dataset that was complied as a combination of PC algorithm search and outside knowledge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MANUAL ENTRY\n",
    "# Enter nodes and edges here\n",
    "# Note: do not run if using option 1 or 2 because this will overwrite process\n",
    "from graphs import standard_synthetic, mixed_synthetic, diabetes\n",
    "\n",
    "\n",
    "\n",
    "nodes = standard_synthetic[\"nodes\"]\n",
    "\n",
    "# DAG\n",
    "edges = standard_synthetic[\"edges\"]\n",
    "\n",
    "# ADMG\n",
    "di_edges = mixed_synthetic[\"di_edges\"]\n",
    "bi_edges = mixed_synthetic[\"bi_edges\"]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Dictionary\n",
    "\n",
    "The data about a graph is held in a graph dictionary for ease of use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR DAG\n",
    "\n",
    "current_graph = {\n",
    "    \"data\": DATA,\n",
    "    \"outcome\": OUTCOME,\n",
    "    \"nodes\": nodes,\n",
    "    \"edges\": edges\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FOR ADMG\n",
    "\n",
    "current_graph = {\n",
    "    \"data\": DATA,\n",
    "    \"outcome\": OUTCOME,\n",
    "    \"nodes\": nodes,\n",
    "    \"di_edges\": di_edges,\n",
    "    \"bi_edges\": bi_edges,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring Causal Features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Option 1: Using Augmented IPW, Frontdoor IPW, and IV Adjustment\n",
    "\n",
    "(There is no other option)\n",
    "\n",
    "Systematically calculate the causal effect of each node on the outcome.\n",
    "\n",
    "For ADMGs if a valid adjusment set cannot be found then it attempts frontdoor then IV.\n",
    "\n",
    "If there is no causal effect the effect is set to -1.0, if the effect cannot be computed using Augmented IPW, Frontdoor IPW, or IV Adjustment then the effect is set to 0.0 because it was unable to be determined. \n",
    "\n",
    "The scores output below are in order of most causally predictive of the outcome and thus should be ideal for training a ML model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS FOR DAGs\n",
    "\n",
    "from findsubset import calculate_causal_scores_DAG\n",
    "\n",
    "scores = calculate_causal_scores_DAG(df, nodes, edges, OUTCOME)\n",
    "\n",
    "pprint(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### USE THIS FOR ADMGs\n",
    "\n",
    "from findsubset import calculate_causal_scores_ADMG\n",
    "\n",
    "scores = calculate_causal_scores_ADMG(df, nodes, di_edges, bi_edges, OUTCOME)\n",
    "\n",
    "pprint(scores)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning\n",
    "\n",
    "I implemented several different machine learning algorithms to use along with the feature selection.\n",
    "\n",
    "During testing, all models perform significantly better when using an ideal subset (determined causally) compared to a random one.\n",
    "\n",
    "Models Implemented:\n",
    "\n",
    "- Logistic Regression\n",
    "- Decision Trees\n",
    "- Boosted Decision Trees\n",
    "- Bagged Decision Trees\n",
    "- Random Forrests\n",
    "- Feedforward Neural Network\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 3\n",
    "\n",
    "sorted_causers = list(scores.keys())\n",
    "ideal_subset = sorted_causers[:SUBSET_SIZE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from learning import prepare_data, LogisticRegression, DecisionTree, BaggedDecisionTree, BoostedDecisionTree, RandomForrest, NeuralNetwork\n",
    "feats, Xtrain, Ytrain, Xtest, Ytest = prepare_data(DATA, NUM_TRAIN, OUTCOME, offset=True, n=SUBSET_SIZE, subset=ideal_subset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "model = LogisticRegression(len(feats))\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Accuracy:\", model.evaluate(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No longer want the offset term\n",
    "feats, Xtrain, Ytrain, Xtest, Ytest = prepare_data(DATA, NUM_TRAIN, OUTCOME, offset=False, n=SUBSET_SIZE, subset=ideal_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "model = DecisionTree()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Accuracy:\", model.evaluate(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boosted Decision Tree\n",
    "\n",
    "model = BoostedDecisionTree()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Accuracy:\", model.evaluate(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bagged Decision Tree\n",
    "\n",
    "model = BaggedDecisionTree()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Accuracy:\", model.evaluate(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forrest\n",
    "\n",
    "model = RandomForrest()\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Accuracy:\", model.evaluate(Xtest, Ytest))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network\n",
    "model = NeuralNetwork(len(feats))\n",
    "model.fit(Xtrain, Ytrain)\n",
    "print(\"Accuracy:\", model.evaluate(Xtest, Ytest))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests\n",
    "\n",
    "I ran tests over all subsets for synthetic and diabetes data to determine whether or not the \"ideal subset\" actually performed better predictions. I found that expecially at lower subset sizes, like 2-4 it makes a huge difference. Specifically with the diabetes data, it was basically able to match a model trained on all features with only the features glucose level and age available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import test_subsets\n",
    "\n",
    "model_to_test = RandomForrest\n",
    "needs_input = False\n",
    "\n",
    "# Note needs_inputsize should be true for LogisticRegression and NeuralNetwork\n",
    "for i in range(len(df.columns) - 1):\n",
    "    naive, rand, ideal = test_subsets(model_to_test, current_graph, n=i, needs_inputsize=True)\n",
    "    print(str(i) + \":\")\n",
    "    print(\"Naive:\", naive)\n",
    "    print(\"Random:\", rand)\n",
    "    print(\"Ideal:\", ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tests import test_subsets\n",
    "\n",
    "models = [LogisticRegression, DecisionTree, BoostedDecisionTree, BaggedDecisionTree, RandomForrest, NeuralNetwork]\n",
    "needs_input = [True, False, False, False, False, True]\n",
    "subset_size = 3\n",
    "\n",
    "# Note needs_inputsize should be true for LogisticRegression and NeuralNetwork\n",
    "for mod, needs in zip(models, needs_input):\n",
    "    naive, rand, ideal = test_subsets(mod, current_graph, n=subset_size, needs_inputsize=needs)\n",
    "    print(str(mod) + \":\")\n",
    "    print(\"Naive:\", naive)\n",
    "    print(\"Random:\", rand)\n",
    "    print(\"Ideal:\", ideal)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cff-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8bf6e8a02171e3dad54acf31bb56e7b7a654943047f9d956a29a6b2b63f66a47"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
